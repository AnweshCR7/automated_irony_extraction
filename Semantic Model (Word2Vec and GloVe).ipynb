{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDownloading emoji data ...\u001b[0m\n",
      "\u001b[92m... OK\u001b[0m (Got response in 3.10 seconds)\n",
      "\u001b[33mWriting emoji data to /Users/anweshcr7/.demoji/codes.json ...\u001b[0m\n",
      "\u001b[92m... OK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import demoji\n",
    "demoji.download_codes()\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some additional imports\n",
    "# from autocorrect import speller\n",
    "stopwordsList = stopwords.words('english')\n",
    "# ended up lemmatizing instead of stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(fp):\n",
    "    '''\n",
    "    Loads the dataset file with label-tweet on each line and parses the dataset.\n",
    "    :param fp: filepath of dataset\n",
    "    :return:\n",
    "        corpus: list of tweet strings of each tweet.\n",
    "        y: list of labels\n",
    "    '''\n",
    "    y = []\n",
    "    corpus = []\n",
    "    with open(fp, 'rt') as data_in:\n",
    "        for line in data_in:\n",
    "            if not line.lower().startswith(\"tweet index\"): # discard first line if it contains metadata\n",
    "                line = line.rstrip() # remove trailing whitespace\n",
    "                label = int(line.split(\"\\t\")[1])\n",
    "                tweet = line.split(\"\\t\")[2]\n",
    "                y.append(label)\n",
    "                corpus.append(tweet)\n",
    "\n",
    "    return corpus, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"I can't breathe!\" was chosen as the most nota...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  Sweet United Nations video. Just in time for C...      1\n",
       "1  @mrdahl87 We are rumored to have talked to Erv...      1\n",
       "2  Hey there! Nice to see you Minnesota/ND Winter...      1\n",
       "3                3 episodes left I'm dying over here      0\n",
       "4  \"I can't breathe!\" was chosen as the most nota...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "train_data, train_label = parse_dataset('SemEval2018-T3-train-taskA_emoji.txt')\n",
    "df_train = pd.DataFrame(np.array(train_data).reshape(3834,1), columns = ['tweet'])\n",
    "df_train['label'] = np.array(train_label).reshape(3834,1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@Callisto1947 Can U Help?||More conservatives ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>#NOT GONNA WIN http://t.co/Mc9ebqjAqj</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@mickymantell He is exactly that sort of perso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>So much #sarcasm at work mate 10/10 #boring 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  @Callisto1947 Can U Help?||More conservatives ...      0\n",
       "1  Just walked in to #Starbucks and asked for a \"...      1\n",
       "2              #NOT GONNA WIN http://t.co/Mc9ebqjAqj      0\n",
       "3  @mickymantell He is exactly that sort of perso...      0\n",
       "4  So much #sarcasm at work mate 10/10 #boring 10...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data\n",
    "test_data, test_label = parse_dataset('SemEval2018-T3_gold_test_taskA_emoji.txt')\n",
    "df_test = pd.DataFrame(np.array(test_data).reshape(784,1), columns = ['tweet'])\n",
    "df_test['label'] = np.array(test_label).reshape(784,1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_eazAUaoc4e"
   },
   "source": [
    "# Project Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9h9ib5NpUapx"
   },
   "source": [
    "## Setup project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtRe6re-UiFd"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKOH2YI0UPs5"
   },
   "source": [
    "## Clean and augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RWIq7xsJjDXC"
   },
   "outputs": [],
   "source": [
    "# Get users' texts as well as corresponding sentiments\n",
    "texts_train = df_train.iloc[:, 0].values\n",
    "texts_test = df_test.iloc[:, 0].values\n",
    "labels_train = df_train.iloc[:, 1].values\n",
    "labels_test = df_test.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean texts\n",
    "clean_texts_train = []\n",
    "clean_texts_test = []\n",
    "for text in texts_train:\n",
    "    # remove all special characters\n",
    "    clean_text = re.sub(r'\\W', ' ', str(text))\n",
    "    # remove all single character\n",
    "    clean_text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', clean_text)\n",
    "    # replace multiple spaces to single space\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text, flags=re.I)\n",
    "    # to lower case\n",
    "    clean_text = clean_text.lower()\n",
    "    clean_texts_train.append(clean_text)\n",
    "    \n",
    "for text in texts_test:\n",
    "    # remove all special characters\n",
    "    clean_text = re.sub(r'\\W', ' ', str(text))\n",
    "    # remove all single character\n",
    "    clean_text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', clean_text)\n",
    "    # replace multiple spaces to single space\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text, flags=re.I)\n",
    "    # to lower case\n",
    "    clean_text = clean_text.lower()\n",
    "    clean_texts_test.append(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine positive and neutral\n",
    "clean_sentiments_train = []\n",
    "clean_sentiments_test = []\n",
    "for label in labels_train:\n",
    "    if label == \"positive\" or label == \"neutral\":\n",
    "        clean_sentiment = \"non-negative\"\n",
    "    else:\n",
    "        clean_sentiment = label\n",
    "    clean_sentiments_train.append(clean_sentiment)\n",
    "    \n",
    "for label in labels_test:\n",
    "    if label == \"positive\" or label == \"neutral\":\n",
    "        clean_sentiment = \"non-negative\"\n",
    "    else:\n",
    "        clean_sentiment = label\n",
    "    clean_sentiments_test.append(clean_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(clean_sentiments_train != labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZC57Kgj-XTIr"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sATZqo_gXhbt"
   },
   "source": [
    "## Build the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train = clean_texts_train\n",
    "X_test = clean_texts_test\n",
    "y_train = labels_train\n",
    "y_test = labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLbT1085X90J"
   },
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_VdlLSvY5lm"
   },
   "source": [
    "## Build the model and train on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_train = [w for w in X_train if not w in stopwords.words(\"english\")]\n",
    "words_test = [w for w in X_test if not w in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Model using external 1.4G Twitter embedding 100 Dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-09 11:48:02,162 : INFO : converting 1193517 vectors from glove.twitter.27B.100d.txt to gensim_glove_vectors.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1193517, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_input_file=\"glove.twitter.27B.100d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-09 11:48:22,779 : INFO : loading projection weights from gensim_glove_vectors.txt\n",
      "2020-03-09 11:50:05,751 : WARNING : duplicate word '<unk>' in gensim_glove_vectors.txt, ignoring all but first\n",
      "2020-03-09 11:50:05,752 : WARNING : duplicate word '<unk>' in gensim_glove_vectors.txt, ignoring all but first\n",
      "2020-03-09 11:50:05,752 : INFO : duplicate words detected, shrinking matrix size from 1193517 to 1193515\n",
      "2020-03-09 11:50:05,753 : INFO : loaded (1193515, 100) matrix from gensim_glove_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 1000   # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-4   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training word2vec using tokenised training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-11 11:33:45,472 : INFO : collecting all words and their counts\n",
      "2020-03-11 11:33:45,487 : WARNING : Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "2020-03-11 11:33:45,490 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-03-11 11:33:45,528 : INFO : collected 66 word types from a corpus of 308795 raw words and 3834 sentences\n",
      "2020-03-11 11:33:45,530 : INFO : Loading a fresh vocabulary\n",
      "2020-03-11 11:33:45,532 : INFO : effective_min_count=40 retains 38 unique words (57% of original 66, drops 28)\n",
      "2020-03-11 11:33:45,533 : INFO : effective_min_count=40 leaves 308761 word corpus (99% of original 308795, drops 34)\n",
      "2020-03-11 11:33:45,534 : INFO : deleting the raw counts dictionary of 66 items\n",
      "2020-03-11 11:33:45,535 : INFO : sample=0.0001 downsamples 38 most-common words\n",
      "2020-03-11 11:33:45,537 : INFO : downsampling leaves estimated 16781 word corpus (5.4% of prior 308761)\n",
      "2020-03-11 11:33:45,540 : INFO : estimated required memory for 38 words and 1000 dimensions: 323000 bytes\n",
      "2020-03-11 11:33:45,541 : INFO : resetting layer weights\n",
      "2020-03-11 11:33:45,563 : INFO : training model with 4 workers on 38 vocabulary and 1000 features, using sg=0 hs=0 sample=0.0001 negative=5 window=10\n",
      "2020-03-11 11:33:45,628 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-11 11:33:45,629 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-11 11:33:45,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-11 11:33:45,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-11 11:33:45,632 : INFO : EPOCH - 1 : training on 308795 raw words (16632 effective words) took 0.1s, 289362 effective words/s\n",
      "2020-03-11 11:33:45,691 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-11 11:33:45,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-11 11:33:45,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-11 11:33:45,693 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-11 11:33:45,694 : INFO : EPOCH - 2 : training on 308795 raw words (16851 effective words) took 0.1s, 326824 effective words/s\n",
      "2020-03-11 11:33:45,748 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-11 11:33:45,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-11 11:33:45,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-11 11:33:45,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-11 11:33:45,752 : INFO : EPOCH - 3 : training on 308795 raw words (16964 effective words) took 0.1s, 337837 effective words/s\n",
      "2020-03-11 11:33:45,808 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-11 11:33:45,810 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-11 11:33:45,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-11 11:33:45,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-11 11:33:45,811 : INFO : EPOCH - 4 : training on 308795 raw words (16977 effective words) took 0.1s, 310529 effective words/s\n",
      "2020-03-11 11:33:45,868 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-11 11:33:45,870 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-11 11:33:45,871 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-11 11:33:45,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-11 11:33:45,872 : INFO : EPOCH - 5 : training on 308795 raw words (16904 effective words) took 0.1s, 303616 effective words/s\n",
      "2020-03-11 11:33:45,873 : INFO : training on a 1543975 raw words (84328 effective words) took 0.3s, 272868 effective words/s\n",
      "2020-03-11 11:33:45,875 : INFO : saving Word2Vec object under wv_tweet, separately None\n",
      "2020-03-11 11:33:45,880 : INFO : not storing attribute vectors_norm\n",
      "2020-03-11 11:33:45,883 : INFO : not storing attribute cum_table\n",
      "2020-03-11 11:33:45,898 : INFO : saved wv_tweet\n"
     ]
    }
   ],
   "source": [
    "# Apply word2vec to train the model\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(words_train, workers=num_workers, size=num_features, \n",
    "                          min_count = min_word_count, window = context, \n",
    "                          sample = downsampling)\n",
    "model_name = \"wv_tweet\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average all word vectors in a paragraph\n",
    "def featureVecMethod(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain feature representation based on the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 3834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anweshcr7/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 3834\n",
      "Review 2000 of 3834\n",
      "Review 3000 of 3834\n",
      "Review 0 of 784\n"
     ]
    }
   ],
   "source": [
    "# Pass glove_model for external corpus\n",
    "# wv_tweet for \n",
    "\n",
    "trainDataVecs=getAvgFeatureVecs(words_train, glove_model, 100)\n",
    "testDataVecs=getAvgFeatureVecs(words_test, glove_model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(trainDataVecs, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMFA8xOXgRJ1"
   },
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SD-jt7gzgXIh",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61       473\n",
      "           1       0.46      0.55      0.50       311\n",
      "\n",
      "    accuracy                           0.56       784\n",
      "   macro avg       0.56      0.56      0.55       784\n",
      "weighted avg       0.58      0.56      0.56       784\n",
      "\n",
      "Accuracy: 0.5599489795918368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "pred = forest.predict(testDataVecs)\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "svc_param_selection(trainDataVecs, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5803571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.56      0.62       473\n",
      "           1       0.48      0.62      0.54       311\n",
      "\n",
      "    accuracy                           0.58       784\n",
      "   macro avg       0.58      0.59      0.58       784\n",
      "weighted avg       0.60      0.58      0.58       784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "clf = svm.SVC(C=10, gamma = 1, kernel = 'rbf')\n",
    "clf.fit(trainDataVecs, y_train)\n",
    "y_pred = clf.predict(testDataVecs)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotCM(cm):\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt=\"d\"); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['Irony', 'Non-Irony']); ax.yaxis.set_ticklabels(['Irony', 'Non-Irony']);\n",
    "\n",
    "svm_cm = confusion_matrix(y_test, y_pred)\n",
    "plotCM(svm_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "_Konigle_Challenge_NLP_Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
